{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Opérations sur les tenseurs avec einops\n",
        "\n",
        "L'idée est de :\n",
        "1. manipuler les tenseurs et les multiplier\n",
        "2. visualiser l'extraction de\n",
        "  - patchs dans des images\n",
        "  - tubelets dans des videos\n",
        "  \n",
        "Pour bien comprendre comment on les réarrange spatialement, temporellement\n",
        "\n",
        "les manipulations de dimensions peuvent se faire :\n",
        "- avec torch (squeeze, stack, permute, reshape, transpose)\n",
        "- avec **einops** : une librairie qui rend les choses plus lisibles et plus stables\n",
        "\n",
        "Ce tuto utilise le plus souvent **einops**."
      ],
      "metadata": {
        "id": "9wMHWM-QnqP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Déja, on fait les install et les imports"
      ],
      "metadata": {
        "id": "d40F56BmoQ3b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyBnVN2RepmM",
        "outputId": "df1b95e6-2840-4f84-d3b4-cec16284327e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.12/dist-packages (0.0.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from torchviz) (2.9.0+cpu)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from torchviz) (0.21)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->torchviz) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->torchviz) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->torchviz) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchviz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torchviz import make_dot\n",
        "\n",
        "import einops\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "iEtoKo0Ae1aI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrice x tenseur d'ordre 3\n",
        "\n",
        "Ici, on commence ce qui m'intéresse, car c'est ce qui se passe quand on passe\n",
        "une phrase dans un transformer.\n",
        "\n",
        "- chaque mot (token) est encodé en un vecteur de shape $(s_{token},)$. Ci dessous : $s_{token} = 2$\n",
        "- Une phrase est une sequence de token. c'est une matrice de shape $(s_{seq},s_{token})$. Ci dessous : ($s_{seq} =3$)\n",
        "- un batch de phrase est un tenseur de shape $(s_{batch},s_{seq},s_{token})$. Ci dessous $s_{batch} = 4$\n",
        "\n",
        "Prenons un MLP qui travaillerait sur chaque token indépendamment,\n",
        "pour chaque composante du token, il calcule une nouvelle sortie.\n",
        "\n",
        "Si la dimension de sortie est aussi $s_{token}$, sa matrice est de shape $(s_{token},s_{token})$\n",
        "\n",
        "- Si on applique cette matrice à un token (vecteur), la sortie est un vecteur, tout se passe comme prévu.\n",
        "- Si on applique cette matrice à une sequence de token (une matrice), la sortie est le resultat d'une multiplication matricielle. Il faut **faire attention à ne pas faire d'opérations entre composantes de tokens différents**.\n",
        "\n",
        "On travaille bien sous forme $input \\times Matrice$ , et tout va bien.\n",
        "\n",
        "Pour être bien propre, on va mettre les opérations effectuées sur chaque token en **ligne** dans la matrice initiale, puis **la transposer**."
      ],
      "metadata": {
        "id": "Lwv_ZrPWv0D_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# prenons une matrice qui calcule, pour un token, la somme et la différence de ses composantes\n",
        "W = torch.Tensor([[1,1],[1,-1]]).float().to(device)\n",
        "# on transpose car on multiplie par la gauche.\n",
        "W = einops.rearrange(W, \"h w -> w h\" )\n",
        "print (\"W\",W)\n",
        "\n",
        "# le premier token de la premiere phrase est [1,2]. le second est [3,4]...\n",
        "# le premier token de la seconde phrase est [11,12]. le second est [13,14]\n",
        "phrase = torch.tensor([[1,2],[3,4],[5,6]]).float().to(device)\n",
        "print(\"\\nshape d'une phrase\",phrase.shape)\n",
        "print(\"\\nexemple de phrase\\n\",phrase)\n",
        "\n",
        "print (\"\\n==========BATCHS de phrase (PAR LA GAUCHE) ===============\\n\")\n",
        "# on stack sur b.\n",
        "batch = einops.rearrange([phrase,phrase + 10,phrase + 100,phrase + 1000], \"b nseq embed -> b nseq embed\")\n",
        "print(\"\\nun batch de 4 phrases\\n\",batch.int())\n",
        "\n",
        "res = batch @ W\n",
        "print(\"resultat\\n\",res.int())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFuMB_ViDDp0",
        "outputId": "4df3380b-eb58-4bac-e884-9451a1c38571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W tensor([[ 1.,  1.],\n",
            "        [ 1., -1.]])\n",
            "\n",
            "shape d'une phrase torch.Size([3, 2])\n",
            "\n",
            "exemple de phrase\n",
            " tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "\n",
            "==========BATCHS de phrase (PAR LA GAUCHE) ===============\n",
            "\n",
            "\n",
            "un batch de 4 phrases\n",
            " tensor([[[   1,    2],\n",
            "         [   3,    4],\n",
            "         [   5,    6]],\n",
            "\n",
            "        [[  11,   12],\n",
            "         [  13,   14],\n",
            "         [  15,   16]],\n",
            "\n",
            "        [[ 101,  102],\n",
            "         [ 103,  104],\n",
            "         [ 105,  106]],\n",
            "\n",
            "        [[1001, 1002],\n",
            "         [1003, 1004],\n",
            "         [1005, 1006]]], dtype=torch.int32)\n",
            "resultat\n",
            " tensor([[[   3,   -1],\n",
            "         [   7,   -1],\n",
            "         [  11,   -1]],\n",
            "\n",
            "        [[  23,   -1],\n",
            "         [  27,   -1],\n",
            "         [  31,   -1]],\n",
            "\n",
            "        [[ 203,   -1],\n",
            "         [ 207,   -1],\n",
            "         [ 211,   -1]],\n",
            "\n",
            "        [[2003,   -1],\n",
            "         [2007,   -1],\n",
            "         [2011,   -1]]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INTERPRETATIONS DE CES MULTIPLICATIONS : BROADCASTING\n",
        "\n",
        "lu quelque part :\n",
        "> \"The matrix multiplication(s) are done between the last two dimensions. The remaining first three dimensions are broadcast and are ‘batch’\"\n",
        "\n",
        "testons ca. Ici, on a\n",
        "\n",
        "- un tenseur $W_{batch}$ de shape $[2,2,2]$ qui représente 2 matrices empilées\n",
        "- un tenseur $batch$ de shape $[4,2,3,2]$ qui représente nos inputs. on va les imaginer comme 4 images de 2 canaux, 3 lignes 2 colonnes.\n",
        "\n",
        "Pour bien s'assurer de ce que l'on fait, vu les égalités de longueur des shape, précisons l'ordre des canaux pour $batch$ : $[B, C, H, W]$\n",
        "\n",
        "Pour la matrice, la shape est $[C, H, W]$\n",
        "\n",
        "On calcule $ batch \\times W_{batch}$.\n",
        "\n",
        "Le résultat est surprenant :\n",
        "\n",
        "- la premiere matrice de $W_{batch}$ multiplie le premier canal d'une image.\n",
        "- la seconde matrice de $W_{batch}$ multiplie le second canal d'une image.\n",
        "- ces opérations sont répétées pour chaque image\n",
        "\n",
        "\n",
        "\n",
        "Ceci est lié au fait que la multiplication **broadcaste** les données : https://docs.pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics\n",
        "\n",
        "le **broadcast** dans la multiplication matricielle a des comportements differents en fonction des tailles des dimensions respectives des tenseurs.\n",
        "\n",
        "Pour savoir s'il faut et si on peut broadcaster, **on regarde les dimensions en partant de la fin et en remontant vers le début**\n",
        "\n",
        "1. Pour *matmult* : les deux dernieres dimensions doivent être compatibles pour une multiplication matricielle.\n",
        "\n",
        "2. comme la troisieme dimension en partant de la fin est de même taille dans les deux tenseurs, tout se passe comme si on appliquait les calculs dans les dimensions suivantes de façon parallele. Ceci explique comment on ferait un calcul d'un tenseur de shape $[C,H,W] \\times$ un tenseur de shape $[C,H,W]$ :\n",
        "**chaque matrice $[H,W]$ des inputs est multipliée par la matrice $[H,W]$ correspondante du tenseur.**\n",
        "\n",
        "3. Pour la partie batch, la 4eme dimension en partant de la fin n'existe pas dans W. Pas de problème, le broadcast va la créer et dupliquer les données.\n",
        "Pour imaginer ca, disons qu'un scalaire $a$, ca peut se broadcaster en un vecteur $[a,a,a,a]$. **Notons que** $a$ **pourrait être un vecteur ou une matrice, ca marcherait pareil**. Donc le tenseur $W_{batch}$ va être étendu pour\n",
        "appliquer l'opération 2 pour chaque \"phrase\" de $batch$\n",
        "\n",
        "4. on s'en servira plus loin, mais une dimension de 1 peut aussi se broadcaster par duplication. Pour imaginer ca, disons qu'une matrice 1,2 telle que $[[1,2,3]]$ peut se broadcaster en une matrice 3,2 : $[[1,2,3],[1,2,3],[1,2,3]]$\n"
      ],
      "metadata": {
        "id": "aYAWrOD8aBZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# on prépare une liste de matrice.\n",
        "# W1 va conserver la premiere composante d'un token.\n",
        "W1 = torch.tensor([[1,0],[0,0]]).float().to(device)\n",
        "W1 = einops.rearrange(W1, \"h w -> w h\" )\n",
        "\n",
        "# Pour X, on va creer un tenseur [b C H W] (4 2 3 2) a partir des données précédentes\n",
        "# le second canal d'une image est simplement l'opposé du premier\n",
        "batch_im = einops.rearrange([batch,-batch], \"c b h w -> b c h w\")\n",
        "\n",
        "# on batche les matrices\n",
        "W_batch = einops.rearrange([W,W1],\"b h w -> b h w\")\n",
        "print(\"\\nW_batch\\n\",W_batch)\n",
        "\n",
        "print(\"batch.shape\",batch_im.shape,\"W.shape\",W_batch.shape)\n",
        "\n",
        "res = batch_im @ W_batch\n",
        "\n",
        "print(\"\\nbatch d'images\\n\",batch_im.int())\n",
        "\n",
        "print(\"\\nres\\n\",res.int())\n",
        "\n",
        "print(\"batch.shape\",batch_im.shape,\"W.shape\",W_batch.shape,\"res.shape :\",res.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnH_AxQ8bazs",
        "outputId": "1a2154bb-79e0-431f-c7dc-a75e355d85a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "W_batch\n",
            " tensor([[[ 1.,  1.],\n",
            "         [ 1., -1.]],\n",
            "\n",
            "        [[ 1.,  0.],\n",
            "         [ 0.,  0.]]])\n",
            "batch.shape torch.Size([4, 2, 3, 2]) W.shape torch.Size([2, 2, 2])\n",
            "\n",
            "batch d'images\n",
            " tensor([[[[    1,     2],\n",
            "          [    3,     4],\n",
            "          [    5,     6]],\n",
            "\n",
            "         [[   -1,    -2],\n",
            "          [   -3,    -4],\n",
            "          [   -5,    -6]]],\n",
            "\n",
            "\n",
            "        [[[   11,    12],\n",
            "          [   13,    14],\n",
            "          [   15,    16]],\n",
            "\n",
            "         [[  -11,   -12],\n",
            "          [  -13,   -14],\n",
            "          [  -15,   -16]]],\n",
            "\n",
            "\n",
            "        [[[  101,   102],\n",
            "          [  103,   104],\n",
            "          [  105,   106]],\n",
            "\n",
            "         [[ -101,  -102],\n",
            "          [ -103,  -104],\n",
            "          [ -105,  -106]]],\n",
            "\n",
            "\n",
            "        [[[ 1001,  1002],\n",
            "          [ 1003,  1004],\n",
            "          [ 1005,  1006]],\n",
            "\n",
            "         [[-1001, -1002],\n",
            "          [-1003, -1004],\n",
            "          [-1005, -1006]]]], dtype=torch.int32)\n",
            "\n",
            "res\n",
            " tensor([[[[    3,    -1],\n",
            "          [    7,    -1],\n",
            "          [   11,    -1]],\n",
            "\n",
            "         [[   -1,     0],\n",
            "          [   -3,     0],\n",
            "          [   -5,     0]]],\n",
            "\n",
            "\n",
            "        [[[   23,    -1],\n",
            "          [   27,    -1],\n",
            "          [   31,    -1]],\n",
            "\n",
            "         [[  -11,     0],\n",
            "          [  -13,     0],\n",
            "          [  -15,     0]]],\n",
            "\n",
            "\n",
            "        [[[  203,    -1],\n",
            "          [  207,    -1],\n",
            "          [  211,    -1]],\n",
            "\n",
            "         [[ -101,     0],\n",
            "          [ -103,     0],\n",
            "          [ -105,     0]]],\n",
            "\n",
            "\n",
            "        [[[ 2003,    -1],\n",
            "          [ 2007,    -1],\n",
            "          [ 2011,    -1]],\n",
            "\n",
            "         [[-1001,     0],\n",
            "          [-1003,     0],\n",
            "          [-1005,     0]]]], dtype=torch.int32)\n",
            "batch.shape torch.Size([4, 2, 3, 2]) W.shape torch.Size([2, 2, 2]) res.shape : torch.Size([4, 2, 3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Broadcasting reloaded\n",
        "\n",
        "Vu la doc, on va tester ceci : appliquer une deuxieme transformation à chacun de nos tokens.\n",
        "\n",
        "On va modifier les inputs pour creer une dimension juste avant les deux dernieres, pour avoir : $[B, C,1, H, W]$\n",
        "\n",
        "la matrice est de shape : [2,H,W]\n",
        "\n",
        "On calcule X @ W\n",
        "\n",
        "cette fois ci, chaque matrice H,W des données passe dans chacune des deux matrices de traitement.\n",
        "\n",
        "Le broadcasting a en fait dupliqué les données des dimensions suivantes dans la dimension de taille 1 pour égaler la taille 2. Puis on applique la strat précédente.\n",
        "\n",
        "**Ce sont des manipulations comme celle ci (et celles d'avant) qui permettent de faire de l'attention spatiale ou temporelle à moindre frais** : on va selectionner des vecteurs pertinents par permutation, pour les batcher.\n",
        "\n",
        "**a noter : dans un cadre opérationnel, vu les résultats ci dessous, il faudrait peut être permuter les dimensions du résultat** pour que les 2 calculs effectués sur chaque token soient la deuxieme dimension en partant de la fin.\n",
        "\n",
        "En l'état, à la sortie, j'ai une shape $[B,C,n_{op},H, W]$\n"
      ],
      "metadata": {
        "id": "l4tjQNi61dCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_reshaped = einops.rearrange(batch_im, \"b c h w -> b c 1 h w\")\n",
        "print (\"\\nbatch reshaped\\n\",X_reshaped.int())\n",
        "\n",
        "res = X_reshaped @ W_batch\n",
        "print(\"\\nres\\n\",res.int())\n",
        "\n",
        "print(\"X.shape\",X_reshaped.shape,\"W.shape\",W_batch.shape,\"res.shape :\",res.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoSszyJP17_E",
        "outputId": "2e152aac-a4d4-40c8-a031-3ee5010d04c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "batch reshaped\n",
            " tensor([[[[[    1,     2],\n",
            "           [    3,     4],\n",
            "           [    5,     6]]],\n",
            "\n",
            "\n",
            "         [[[   -1,    -2],\n",
            "           [   -3,    -4],\n",
            "           [   -5,    -6]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[   11,    12],\n",
            "           [   13,    14],\n",
            "           [   15,    16]]],\n",
            "\n",
            "\n",
            "         [[[  -11,   -12],\n",
            "           [  -13,   -14],\n",
            "           [  -15,   -16]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[  101,   102],\n",
            "           [  103,   104],\n",
            "           [  105,   106]]],\n",
            "\n",
            "\n",
            "         [[[ -101,  -102],\n",
            "           [ -103,  -104],\n",
            "           [ -105,  -106]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[ 1001,  1002],\n",
            "           [ 1003,  1004],\n",
            "           [ 1005,  1006]]],\n",
            "\n",
            "\n",
            "         [[[-1001, -1002],\n",
            "           [-1003, -1004],\n",
            "           [-1005, -1006]]]]], dtype=torch.int32)\n",
            "\n",
            "res\n",
            " tensor([[[[[    3,    -1],\n",
            "           [    7,    -1],\n",
            "           [   11,    -1]],\n",
            "\n",
            "          [[    1,     0],\n",
            "           [    3,     0],\n",
            "           [    5,     0]]],\n",
            "\n",
            "\n",
            "         [[[   -3,     1],\n",
            "           [   -7,     1],\n",
            "           [  -11,     1]],\n",
            "\n",
            "          [[   -1,     0],\n",
            "           [   -3,     0],\n",
            "           [   -5,     0]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[   23,    -1],\n",
            "           [   27,    -1],\n",
            "           [   31,    -1]],\n",
            "\n",
            "          [[   11,     0],\n",
            "           [   13,     0],\n",
            "           [   15,     0]]],\n",
            "\n",
            "\n",
            "         [[[  -23,     1],\n",
            "           [  -27,     1],\n",
            "           [  -31,     1]],\n",
            "\n",
            "          [[  -11,     0],\n",
            "           [  -13,     0],\n",
            "           [  -15,     0]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[  203,    -1],\n",
            "           [  207,    -1],\n",
            "           [  211,    -1]],\n",
            "\n",
            "          [[  101,     0],\n",
            "           [  103,     0],\n",
            "           [  105,     0]]],\n",
            "\n",
            "\n",
            "         [[[ -203,     1],\n",
            "           [ -207,     1],\n",
            "           [ -211,     1]],\n",
            "\n",
            "          [[ -101,     0],\n",
            "           [ -103,     0],\n",
            "           [ -105,     0]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[ 2003,    -1],\n",
            "           [ 2007,    -1],\n",
            "           [ 2011,    -1]],\n",
            "\n",
            "          [[ 1001,     0],\n",
            "           [ 1003,     0],\n",
            "           [ 1005,     0]]],\n",
            "\n",
            "\n",
            "         [[[-2003,     1],\n",
            "           [-2007,     1],\n",
            "           [-2011,     1]],\n",
            "\n",
            "          [[-1001,     0],\n",
            "           [-1003,     0],\n",
            "           [-1005,     0]]]]], dtype=torch.int32)\n",
            "X.shape torch.Size([4, 2, 1, 3, 2]) W.shape torch.Size([2, 2, 2]) res.shape : torch.Size([4, 2, 2, 3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Rearrange dans les images\n",
        "\n",
        "on a une image, composée de 3 canaux, de taille 2 x 4\n",
        "\n",
        "On veut faire un paquet de vecteurs. Chaque vecteur correspond à un pixel et contient les 3 canaux.\n",
        "\n"
      ],
      "metadata": {
        "id": "aoznZIvpTQxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# un canal d'une image\n",
        "imR = torch.tensor([[1,2,3,4],[5,6,7,8]]).float().to(device)\n",
        "# l'image : le seconde canal est le premier + 10, le troisieme premier -10\n",
        "\n",
        "im = einops.rearrange([imR,imR+10,imR-10],\"c h w -> c h w\")\n",
        "\n",
        "print(\"\\nune image \\n\",im)\n",
        "print(\"\\nshape d'une image\",im.shape)\n",
        "\n",
        "# On reshape chaque canal en un vecteur de taille hxw et on transpose...\n",
        "im_reshaped = einops.rearrange(im,\"c h w -> (h w) c\")\n",
        "print(\"\\n après reshape\\n\")\n",
        "print(im_reshaped)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD3Up9J6Ts2H",
        "outputId": "d0ac23e1-1523-4319-9dad-c05334746b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "une image \n",
            " tensor([[[ 1.,  2.,  3.,  4.],\n",
            "         [ 5.,  6.,  7.,  8.]],\n",
            "\n",
            "        [[11., 12., 13., 14.],\n",
            "         [15., 16., 17., 18.]],\n",
            "\n",
            "        [[-9., -8., -7., -6.],\n",
            "         [-5., -4., -3., -2.]]])\n",
            "\n",
            "shape d'une image torch.Size([3, 2, 4])\n",
            "\n",
            " après reshape\n",
            "\n",
            "tensor([[ 1., 11., -9.],\n",
            "        [ 2., 12., -8.],\n",
            "        [ 3., 13., -7.],\n",
            "        [ 4., 14., -6.],\n",
            "        [ 5., 15., -5.],\n",
            "        [ 6., 16., -4.],\n",
            "        [ 7., 17., -3.],\n",
            "        [ 8., 18., -2.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Idem mais avec des patchs\n",
        "\n",
        "- on part d'une image à 2 canaux, de taille 6x4 (c h w)\n",
        "- on va faire des patchs de taille 2x1 (hp x hw) dans cette image.\n",
        "\n",
        "ca va faire une matrice de patchs de taille $[nph, npw]$ pour un total de $nph \\times npw$ patchs\n"
      ],
      "metadata": {
        "id": "kk4jv6PtW9OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "imR = torch.tensor([[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16],[17,18,19,20],[21,22,23,24]]).float().to(device)\n",
        "im = einops.rearrange([imR,imR+100],\"c h w -> c h w\")\n",
        "print(im)\n",
        "\n",
        "\n",
        "# On reshape en patch de taille 1x2...\n",
        "\n",
        "sp_i = 3 # taille des patchs en nb lignes\n",
        "sp_j = 2 #taille des patchs en nb colonnes\n",
        "\n",
        "# en deux étapes pour bien vérifier\n",
        "# on crée les patchs en découpant les H et les W\n",
        "# ca va donner une matrice de patchs\n",
        "# equivalent à (C,H//hp,hp, W//wp,wp)\n",
        "im_reshaped = einops.rearrange(im, \"c (nph hp) (npw wp) -> nph npw c hp wp\", hp=3, wp=2)\n",
        "print(\"\\nmatrice de patchs constitués comme des images (cx3x2)\\n\", im_reshaped)\n",
        "\n",
        "# On fusionne les dimensions finales pour avoir chaque patch sous forme vectorielle\n",
        "# on fusionne aussi les dimensions initiale pour avoir une liste de patchs\n",
        "im_reshaped = einops.rearrange(im_reshaped, \"nph npw c hp wp -> (nph npw) (c hp wp)\")\n",
        "print(\"\\nliste de patchs constitués comme des vecteurs\\n\")\n",
        "print(im_reshaped)\n",
        "\n",
        "print(\"\\nci dessus, j'ai bien une liste de 4 patchs de vecteurs\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sS26YNzeW5jw",
        "outputId": "373299a6-fd4c-462c-8264-09eb08056e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[  1.,   2.,   3.,   4.],\n",
            "         [  5.,   6.,   7.,   8.],\n",
            "         [  9.,  10.,  11.,  12.],\n",
            "         [ 13.,  14.,  15.,  16.],\n",
            "         [ 17.,  18.,  19.,  20.],\n",
            "         [ 21.,  22.,  23.,  24.]],\n",
            "\n",
            "        [[101., 102., 103., 104.],\n",
            "         [105., 106., 107., 108.],\n",
            "         [109., 110., 111., 112.],\n",
            "         [113., 114., 115., 116.],\n",
            "         [117., 118., 119., 120.],\n",
            "         [121., 122., 123., 124.]]])\n",
            "\n",
            "matrice de patchs constitués comme des images (cx3x2)\n",
            " tensor([[[[[  1.,   2.],\n",
            "           [  5.,   6.],\n",
            "           [  9.,  10.]],\n",
            "\n",
            "          [[101., 102.],\n",
            "           [105., 106.],\n",
            "           [109., 110.]]],\n",
            "\n",
            "\n",
            "         [[[  3.,   4.],\n",
            "           [  7.,   8.],\n",
            "           [ 11.,  12.]],\n",
            "\n",
            "          [[103., 104.],\n",
            "           [107., 108.],\n",
            "           [111., 112.]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[ 13.,  14.],\n",
            "           [ 17.,  18.],\n",
            "           [ 21.,  22.]],\n",
            "\n",
            "          [[113., 114.],\n",
            "           [117., 118.],\n",
            "           [121., 122.]]],\n",
            "\n",
            "\n",
            "         [[[ 15.,  16.],\n",
            "           [ 19.,  20.],\n",
            "           [ 23.,  24.]],\n",
            "\n",
            "          [[115., 116.],\n",
            "           [119., 120.],\n",
            "           [123., 124.]]]]])\n",
            "\n",
            "liste de patchs constitués comme des vecteurs\n",
            "\n",
            "tensor([[  1.,   2.,   5.,   6.,   9.,  10., 101., 102., 105., 106., 109., 110.],\n",
            "        [  3.,   4.,   7.,   8.,  11.,  12., 103., 104., 107., 108., 111., 112.],\n",
            "        [ 13.,  14.,  17.,  18.,  21.,  22., 113., 114., 117., 118., 121., 122.],\n",
            "        [ 15.,  16.,  19.,  20.,  23.,  24., 115., 116., 119., 120., 123., 124.]])\n",
            "\n",
            "ci dessus, j'ai bien une liste de 4 patchs de vecteurs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Manipulations spatio temporelles sur des videos\n",
        "\n",
        "A partir d'ici, on a compris que si on rajoute une dimension Batch, les opérations se feront sans difficultés sur chacun des items du batch par brodcasting.\n",
        "\n",
        "On ne travaillera donc plus, pour ces démos, avec des données batchées.\n",
        "\n",
        "#### Préparation d'une vidéo exemple\n",
        "On va se faire une video de 8 images.\n",
        "chaque image a :\n",
        "- 2 canaux ([1,2...] et [-1, -2...])\n",
        "- une taille de 6x4\n",
        "- les différentes images sont calculees comme suit : $im_i = 10^i \\times im_1$\n",
        "\n",
        "Nos données ont une shape : $(frames,C,H,W)$\n",
        "\n",
        "#### Encodage de cette vidéo\n",
        "\n",
        "Le code qui suit permettra de changer les tailles des tubelets.\n",
        "\n",
        "Je note quand meme ci dessous le cas pour lequel les données ont été préparées\n",
        "\n",
        "- On encode en tubelets (patchs) de taille $[fp,hp,wp] = [2,3,2]$\n",
        "\n",
        "Chaque tubelet est donc un patch de 2 frames, s'etendant spatialement sur 3x2 pixels.\n",
        "\n",
        "- Ca fait $(npt\\times nph \\times npw)$ patchs (4x2x2) patchs (16 patchs au total)\n",
        "- chaque patch a une shape $[fp, c, hp, hw]$, soit (2,2,3,2)\n",
        "\n",
        "pour finaliser le traitement,\n",
        "- je vectorise chaque patch : un vecteur de taille $fp \\times c \\times hp \\times hp$, soit (2x2x3x2) = 24\n",
        "- je vectorise l'ensemble des patchs : une liste de taille $npt \\times nh \\times nw$, soit 4x2x2 = 16 patchs\n",
        "\n",
        "Le but du code suivant est de **jouer avec les tailles de tubelets pour comprendre les manips d'extraction de patchs**\n",
        "\n"
      ],
      "metadata": {
        "id": "UIF-jAZzU8yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# une fonction pour faire les patchs\n",
        "# input est une video [frames, C, H, W]\n",
        "def extract_patches(inputs,fp=2, hp=3,wp=2):\n",
        "\n",
        "  # en deux étapes pour bien vérifier\n",
        "  # on crée les patchs en découpant les frames, les H et les W\n",
        "  # ca va donner une matrice de patchs\n",
        "  # equivalent à (f//fp, fp, C,H//hp,hp, W//wp,wp), réorganisés\n",
        "  inputs_reshaped = einops.rearrange(inputs, \"(npt fp) c (nph hp) (npw wp) -> npt nph npw fp c hp wp\", fp=fp, hp=hp, wp=wp)\n",
        "\n",
        "  # On fusionne les dimensions finales pour avoir chaque patch sous forme vectorielle\n",
        "  # on fusionne aussi les dimensions initiale pour avoir une liste de patchs\n",
        "  inputs_reshaped = einops.rearrange(inputs_reshaped, \"npt nph npw fp c hp wp -> npt nph npw (fp c hp wp)\")\n",
        "\n",
        "  return inputs_reshaped\n"
      ],
      "metadata": {
        "id": "TAvMaKBOYB1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = 6\n",
        "w = 4\n",
        "im_1 = torch.tensor([i+1 for i in range(h*w)])\n",
        "im_1 = im_1.reshape(h,w)\n",
        "\n",
        "print(\"im 1\\n\",im_1)\n",
        "\n",
        "# canal 2 : - canal 1\n",
        "im = einops.rearrange([im_1, -im_1],\"c h w -> c h w\")\n",
        "\n",
        "# les differentes frames, frame1, 10 * frame1, 100*frame1,...\n",
        "list_im = [im*(10**(i)) for i in range(8)]\n",
        "\n",
        "vid = torch.stack(list_im)\n",
        "\n",
        "print (\"\\nvid\\n\", vid)\n",
        "print (\"\\nvid shape\\n\", vid.shape)\n",
        "\n",
        "hp = 3  # H = 6   =>  on peut prendre 1, 2, 3 ou 6\n",
        "wp = 2  # W = 4   =>  on peut prendre 1, 2, ou 4\n",
        "fp = 2  # F = 8   =>  on peut prendre 1, 2, 4, ou 8\n",
        "patches = extract_patches(vid, hp = hp, wp=wp, fp=fp)\n",
        "print(\"\\npatches.shape\\n\",patches.shape)\n",
        "print(\"\\n patches\\n\",patches)\n",
        "\n",
        "print(\"on a bien dans un patch : frame initiale channel 1, frame initiale channel 2, frame suivante channel 1 frame suivante channel 2\")\n",
        "print(\"on a bien tous les patchs dans l'ordre : toutes les colonnes, puis toutes les lignes, puis tous les temps\")\n",
        "\n",
        "print(\"\\npatches.shape\\n\",patches.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN2gRaOScfrx",
        "outputId": "21387675-be82-4d12-f807-5a690bd75ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "im 1\n",
            " tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12],\n",
            "        [13, 14, 15, 16],\n",
            "        [17, 18, 19, 20],\n",
            "        [21, 22, 23, 24]])\n",
            "\n",
            "vid\n",
            " tensor([[[[         1,          2,          3,          4],\n",
            "          [         5,          6,          7,          8],\n",
            "          [         9,         10,         11,         12],\n",
            "          [        13,         14,         15,         16],\n",
            "          [        17,         18,         19,         20],\n",
            "          [        21,         22,         23,         24]],\n",
            "\n",
            "         [[        -1,         -2,         -3,         -4],\n",
            "          [        -5,         -6,         -7,         -8],\n",
            "          [        -9,        -10,        -11,        -12],\n",
            "          [       -13,        -14,        -15,        -16],\n",
            "          [       -17,        -18,        -19,        -20],\n",
            "          [       -21,        -22,        -23,        -24]]],\n",
            "\n",
            "\n",
            "        [[[        10,         20,         30,         40],\n",
            "          [        50,         60,         70,         80],\n",
            "          [        90,        100,        110,        120],\n",
            "          [       130,        140,        150,        160],\n",
            "          [       170,        180,        190,        200],\n",
            "          [       210,        220,        230,        240]],\n",
            "\n",
            "         [[       -10,        -20,        -30,        -40],\n",
            "          [       -50,        -60,        -70,        -80],\n",
            "          [       -90,       -100,       -110,       -120],\n",
            "          [      -130,       -140,       -150,       -160],\n",
            "          [      -170,       -180,       -190,       -200],\n",
            "          [      -210,       -220,       -230,       -240]]],\n",
            "\n",
            "\n",
            "        [[[       100,        200,        300,        400],\n",
            "          [       500,        600,        700,        800],\n",
            "          [       900,       1000,       1100,       1200],\n",
            "          [      1300,       1400,       1500,       1600],\n",
            "          [      1700,       1800,       1900,       2000],\n",
            "          [      2100,       2200,       2300,       2400]],\n",
            "\n",
            "         [[      -100,       -200,       -300,       -400],\n",
            "          [      -500,       -600,       -700,       -800],\n",
            "          [      -900,      -1000,      -1100,      -1200],\n",
            "          [     -1300,      -1400,      -1500,      -1600],\n",
            "          [     -1700,      -1800,      -1900,      -2000],\n",
            "          [     -2100,      -2200,      -2300,      -2400]]],\n",
            "\n",
            "\n",
            "        [[[      1000,       2000,       3000,       4000],\n",
            "          [      5000,       6000,       7000,       8000],\n",
            "          [      9000,      10000,      11000,      12000],\n",
            "          [     13000,      14000,      15000,      16000],\n",
            "          [     17000,      18000,      19000,      20000],\n",
            "          [     21000,      22000,      23000,      24000]],\n",
            "\n",
            "         [[     -1000,      -2000,      -3000,      -4000],\n",
            "          [     -5000,      -6000,      -7000,      -8000],\n",
            "          [     -9000,     -10000,     -11000,     -12000],\n",
            "          [    -13000,     -14000,     -15000,     -16000],\n",
            "          [    -17000,     -18000,     -19000,     -20000],\n",
            "          [    -21000,     -22000,     -23000,     -24000]]],\n",
            "\n",
            "\n",
            "        [[[     10000,      20000,      30000,      40000],\n",
            "          [     50000,      60000,      70000,      80000],\n",
            "          [     90000,     100000,     110000,     120000],\n",
            "          [    130000,     140000,     150000,     160000],\n",
            "          [    170000,     180000,     190000,     200000],\n",
            "          [    210000,     220000,     230000,     240000]],\n",
            "\n",
            "         [[    -10000,     -20000,     -30000,     -40000],\n",
            "          [    -50000,     -60000,     -70000,     -80000],\n",
            "          [    -90000,    -100000,    -110000,    -120000],\n",
            "          [   -130000,    -140000,    -150000,    -160000],\n",
            "          [   -170000,    -180000,    -190000,    -200000],\n",
            "          [   -210000,    -220000,    -230000,    -240000]]],\n",
            "\n",
            "\n",
            "        [[[    100000,     200000,     300000,     400000],\n",
            "          [    500000,     600000,     700000,     800000],\n",
            "          [    900000,    1000000,    1100000,    1200000],\n",
            "          [   1300000,    1400000,    1500000,    1600000],\n",
            "          [   1700000,    1800000,    1900000,    2000000],\n",
            "          [   2100000,    2200000,    2300000,    2400000]],\n",
            "\n",
            "         [[   -100000,    -200000,    -300000,    -400000],\n",
            "          [   -500000,    -600000,    -700000,    -800000],\n",
            "          [   -900000,   -1000000,   -1100000,   -1200000],\n",
            "          [  -1300000,   -1400000,   -1500000,   -1600000],\n",
            "          [  -1700000,   -1800000,   -1900000,   -2000000],\n",
            "          [  -2100000,   -2200000,   -2300000,   -2400000]]],\n",
            "\n",
            "\n",
            "        [[[   1000000,    2000000,    3000000,    4000000],\n",
            "          [   5000000,    6000000,    7000000,    8000000],\n",
            "          [   9000000,   10000000,   11000000,   12000000],\n",
            "          [  13000000,   14000000,   15000000,   16000000],\n",
            "          [  17000000,   18000000,   19000000,   20000000],\n",
            "          [  21000000,   22000000,   23000000,   24000000]],\n",
            "\n",
            "         [[  -1000000,   -2000000,   -3000000,   -4000000],\n",
            "          [  -5000000,   -6000000,   -7000000,   -8000000],\n",
            "          [  -9000000,  -10000000,  -11000000,  -12000000],\n",
            "          [ -13000000,  -14000000,  -15000000,  -16000000],\n",
            "          [ -17000000,  -18000000,  -19000000,  -20000000],\n",
            "          [ -21000000,  -22000000,  -23000000,  -24000000]]],\n",
            "\n",
            "\n",
            "        [[[  10000000,   20000000,   30000000,   40000000],\n",
            "          [  50000000,   60000000,   70000000,   80000000],\n",
            "          [  90000000,  100000000,  110000000,  120000000],\n",
            "          [ 130000000,  140000000,  150000000,  160000000],\n",
            "          [ 170000000,  180000000,  190000000,  200000000],\n",
            "          [ 210000000,  220000000,  230000000,  240000000]],\n",
            "\n",
            "         [[ -10000000,  -20000000,  -30000000,  -40000000],\n",
            "          [ -50000000,  -60000000,  -70000000,  -80000000],\n",
            "          [ -90000000, -100000000, -110000000, -120000000],\n",
            "          [-130000000, -140000000, -150000000, -160000000],\n",
            "          [-170000000, -180000000, -190000000, -200000000],\n",
            "          [-210000000, -220000000, -230000000, -240000000]]]])\n",
            "\n",
            "vid shape\n",
            " torch.Size([8, 2, 6, 4])\n",
            "\n",
            "patches.shape\n",
            " torch.Size([16, 24])\n",
            "\n",
            " patches\n",
            " tensor([[         1,          2,          5,          6,          9,         10,\n",
            "                 -1,         -2,         -5,         -6,         -9,        -10,\n",
            "                 10,         20,         50,         60,         90,        100,\n",
            "                -10,        -20,        -50,        -60,        -90,       -100],\n",
            "        [         3,          4,          7,          8,         11,         12,\n",
            "                 -3,         -4,         -7,         -8,        -11,        -12,\n",
            "                 30,         40,         70,         80,        110,        120,\n",
            "                -30,        -40,        -70,        -80,       -110,       -120],\n",
            "        [        13,         14,         17,         18,         21,         22,\n",
            "                -13,        -14,        -17,        -18,        -21,        -22,\n",
            "                130,        140,        170,        180,        210,        220,\n",
            "               -130,       -140,       -170,       -180,       -210,       -220],\n",
            "        [        15,         16,         19,         20,         23,         24,\n",
            "                -15,        -16,        -19,        -20,        -23,        -24,\n",
            "                150,        160,        190,        200,        230,        240,\n",
            "               -150,       -160,       -190,       -200,       -230,       -240],\n",
            "        [       100,        200,        500,        600,        900,       1000,\n",
            "               -100,       -200,       -500,       -600,       -900,      -1000,\n",
            "               1000,       2000,       5000,       6000,       9000,      10000,\n",
            "              -1000,      -2000,      -5000,      -6000,      -9000,     -10000],\n",
            "        [       300,        400,        700,        800,       1100,       1200,\n",
            "               -300,       -400,       -700,       -800,      -1100,      -1200,\n",
            "               3000,       4000,       7000,       8000,      11000,      12000,\n",
            "              -3000,      -4000,      -7000,      -8000,     -11000,     -12000],\n",
            "        [      1300,       1400,       1700,       1800,       2100,       2200,\n",
            "              -1300,      -1400,      -1700,      -1800,      -2100,      -2200,\n",
            "              13000,      14000,      17000,      18000,      21000,      22000,\n",
            "             -13000,     -14000,     -17000,     -18000,     -21000,     -22000],\n",
            "        [      1500,       1600,       1900,       2000,       2300,       2400,\n",
            "              -1500,      -1600,      -1900,      -2000,      -2300,      -2400,\n",
            "              15000,      16000,      19000,      20000,      23000,      24000,\n",
            "             -15000,     -16000,     -19000,     -20000,     -23000,     -24000],\n",
            "        [     10000,      20000,      50000,      60000,      90000,     100000,\n",
            "             -10000,     -20000,     -50000,     -60000,     -90000,    -100000,\n",
            "             100000,     200000,     500000,     600000,     900000,    1000000,\n",
            "            -100000,    -200000,    -500000,    -600000,    -900000,   -1000000],\n",
            "        [     30000,      40000,      70000,      80000,     110000,     120000,\n",
            "             -30000,     -40000,     -70000,     -80000,    -110000,    -120000,\n",
            "             300000,     400000,     700000,     800000,    1100000,    1200000,\n",
            "            -300000,    -400000,    -700000,    -800000,   -1100000,   -1200000],\n",
            "        [    130000,     140000,     170000,     180000,     210000,     220000,\n",
            "            -130000,    -140000,    -170000,    -180000,    -210000,    -220000,\n",
            "            1300000,    1400000,    1700000,    1800000,    2100000,    2200000,\n",
            "           -1300000,   -1400000,   -1700000,   -1800000,   -2100000,   -2200000],\n",
            "        [    150000,     160000,     190000,     200000,     230000,     240000,\n",
            "            -150000,    -160000,    -190000,    -200000,    -230000,    -240000,\n",
            "            1500000,    1600000,    1900000,    2000000,    2300000,    2400000,\n",
            "           -1500000,   -1600000,   -1900000,   -2000000,   -2300000,   -2400000],\n",
            "        [   1000000,    2000000,    5000000,    6000000,    9000000,   10000000,\n",
            "           -1000000,   -2000000,   -5000000,   -6000000,   -9000000,  -10000000,\n",
            "           10000000,   20000000,   50000000,   60000000,   90000000,  100000000,\n",
            "          -10000000,  -20000000,  -50000000,  -60000000,  -90000000, -100000000],\n",
            "        [   3000000,    4000000,    7000000,    8000000,   11000000,   12000000,\n",
            "           -3000000,   -4000000,   -7000000,   -8000000,  -11000000,  -12000000,\n",
            "           30000000,   40000000,   70000000,   80000000,  110000000,  120000000,\n",
            "          -30000000,  -40000000,  -70000000,  -80000000, -110000000, -120000000],\n",
            "        [  13000000,   14000000,   17000000,   18000000,   21000000,   22000000,\n",
            "          -13000000,  -14000000,  -17000000,  -18000000,  -21000000,  -22000000,\n",
            "          130000000,  140000000,  170000000,  180000000,  210000000,  220000000,\n",
            "         -130000000, -140000000, -170000000, -180000000, -210000000, -220000000],\n",
            "        [  15000000,   16000000,   19000000,   20000000,   23000000,   24000000,\n",
            "          -15000000,  -16000000,  -19000000,  -20000000,  -23000000,  -24000000,\n",
            "          150000000,  160000000,  190000000,  200000000,  230000000,  240000000,\n",
            "         -150000000, -160000000, -190000000, -200000000, -230000000, -240000000]])\n",
            "on a bien dans un patch : frame initiale channel 1, frame initiale channel 2, frame suivante channel 1 frame suivante channel 2\n",
            "on a bien tous les patchs dans l'ordre : toutes les colonnes, puis toutes les lignes, puis tous les temps\n",
            "\n",
            "patches.shape\n",
            " torch.Size([16, 24])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "parfait. Le tuto suivant consistera a manipuler des inputs pour faire des manips spatio temporelles dedans"
      ],
      "metadata": {
        "id": "yYM0yJjDcnCi"
      }
    }
  ]
}